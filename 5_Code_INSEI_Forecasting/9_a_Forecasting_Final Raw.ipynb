{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f643dc6d",
   "metadata": {},
   "source": [
    "# Forecasting\n",
    "\n",
    "The following sections detail the econometric and machine learning pipeline used to evaluate the predictive utility of the INSEI sentiment index against the official Consumer Price Index (CPI). \n",
    "\n",
    "The analysis employs a \"Control vs. Test\" experimental design, comparing baseline models (using only historical inflation data) against hybrid models (using historical inflation + news sentiment) across three distinct architectures: Ridge Regression, Vector Autoregression (VAR), and Long Short-Term Memory (LSTM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "430b5ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import os\n",
    "\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "def calculate_metrics(y_true, y_pred, model_name=\"Model\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"--- {model_name} ---\")\n",
    "    print(f\"MAE:  {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R2:   {r2:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    return {\"Model\": model_name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "results_summary = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5ce027",
   "metadata": {},
   "source": [
    "# Data Load & Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a4d065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 78 (Jan 2017 - Dec 2023)\n",
      "Testing Samples:  22  (Jan 2024 - Oct 2025)\n"
     ]
    }
   ],
   "source": [
    "# Load the Aligned Data (Created in File 8)\n",
    "df = pd.read_csv(\"insei_all_model_raw_granger_fullmodif.csv\")\n",
    "df[\"year_month_dt\"] = pd.to_datetime(df[\"year_month_dt\"])\n",
    "df = df.set_index(\"year_month_dt\")\n",
    "\n",
    "# Define Columns\n",
    "TARGET_COL = \"Rate\"\n",
    "SENTIMENT_COLS = [\"insei_indobert_raw\", \"insei_indolem_raw\", \"insei_mdeberta_raw\",\"insei_gemini_raw\"]\n",
    "\n",
    "# Split Train/Test\n",
    "CUTOFF_DATE = \"2024-01-01\"\n",
    "train_df = df[df.index < CUTOFF_DATE].copy()\n",
    "test_df = df[df.index >= CUTOFF_DATE].copy()\n",
    "\n",
    "print(f\"Training Samples: {len(train_df)} (Jan 2017 - Dec 2023)\")\n",
    "print(f\"Testing Samples:  {len(test_df)}  (Jan 2024 - Oct 2025)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc5b573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>insei_indobert_raw</th>\n",
       "      <th>insei_indolem_raw</th>\n",
       "      <th>insei_mdeberta_raw</th>\n",
       "      <th>insei_gemini_raw</th>\n",
       "      <th>insei_indobert_norm</th>\n",
       "      <th>insei_indobert_smooth</th>\n",
       "      <th>insei_indobert_lagged</th>\n",
       "      <th>insei_indobert_final</th>\n",
       "      <th>insei_indolem_norm</th>\n",
       "      <th>...</th>\n",
       "      <th>insei_gemini_norm</th>\n",
       "      <th>insei_gemini_smooth</th>\n",
       "      <th>insei_gemini_lagged</th>\n",
       "      <th>insei_gemini_final</th>\n",
       "      <th>insei_indobert_lagged_raw</th>\n",
       "      <th>insei_indolem_lagged_raw</th>\n",
       "      <th>insei_mdeberta_lagged_raw</th>\n",
       "      <th>insei_gemini_lagged_raw</th>\n",
       "      <th>Rate</th>\n",
       "      <th>year_month_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_month_dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-01</th>\n",
       "      <td>2017-07</td>\n",
       "      <td>-0.078912</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>-0.050584</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.018024</td>\n",
       "      <td>0.264608</td>\n",
       "      <td>0.222023</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2017-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-01</th>\n",
       "      <td>2017-08</td>\n",
       "      <td>-0.052705</td>\n",
       "      <td>0.018444</td>\n",
       "      <td>-0.051758</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.098984</td>\n",
       "      <td>0.229115</td>\n",
       "      <td>0.142892</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>2017-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-01</th>\n",
       "      <td>2017-09</td>\n",
       "      <td>0.044486</td>\n",
       "      <td>0.115167</td>\n",
       "      <td>0.095657</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.078912</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>-0.050584</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2017-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01</th>\n",
       "      <td>2017-10</td>\n",
       "      <td>-0.026432</td>\n",
       "      <td>0.043418</td>\n",
       "      <td>0.026158</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>-0.40897</td>\n",
       "      <td>-0.136323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.639696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.671247</td>\n",
       "      <td>-0.223749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.052705</td>\n",
       "      <td>0.018444</td>\n",
       "      <td>-0.051758</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2017-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01</th>\n",
       "      <td>2017-11</td>\n",
       "      <td>-0.124479</td>\n",
       "      <td>0.053617</td>\n",
       "      <td>-0.018199</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>-1.39928</td>\n",
       "      <td>-0.602750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.500887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044214</td>\n",
       "      <td>-0.209011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.044486</td>\n",
       "      <td>0.115167</td>\n",
       "      <td>0.095657</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2017-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              year_month  insei_indobert_raw  insei_indolem_raw  \\\n",
       "year_month_dt                                                     \n",
       "2017-07-01       2017-07           -0.078912           0.011876   \n",
       "2017-08-01       2017-08           -0.052705           0.018444   \n",
       "2017-09-01       2017-09            0.044486           0.115167   \n",
       "2017-10-01       2017-10           -0.026432           0.043418   \n",
       "2017-11-01       2017-11           -0.124479           0.053617   \n",
       "\n",
       "               insei_mdeberta_raw  insei_gemini_raw  insei_indobert_norm  \\\n",
       "year_month_dt                                                              \n",
       "2017-07-01              -0.050584          0.048780              0.00000   \n",
       "2017-08-01              -0.051758          0.040000              0.00000   \n",
       "2017-09-01               0.095657          0.250000              0.00000   \n",
       "2017-10-01               0.026158          0.081633             -0.40897   \n",
       "2017-11-01              -0.018199          0.163265             -1.39928   \n",
       "\n",
       "               insei_indobert_smooth  insei_indobert_lagged  \\\n",
       "year_month_dt                                                 \n",
       "2017-07-01                  0.000000                    0.0   \n",
       "2017-08-01                  0.000000                    0.0   \n",
       "2017-09-01                  0.000000                    0.0   \n",
       "2017-10-01                 -0.136323                    0.0   \n",
       "2017-11-01                 -0.602750                    0.0   \n",
       "\n",
       "               insei_indobert_final  insei_indolem_norm  ...  \\\n",
       "year_month_dt                                            ...   \n",
       "2017-07-01                     50.0            0.000000  ...   \n",
       "2017-08-01                     50.0            0.000000  ...   \n",
       "2017-09-01                     50.0            0.000000  ...   \n",
       "2017-10-01                     50.0           -0.639696  ...   \n",
       "2017-11-01                     50.0           -0.500887  ...   \n",
       "\n",
       "               insei_gemini_norm  insei_gemini_smooth  insei_gemini_lagged  \\\n",
       "year_month_dt                                                                \n",
       "2017-07-01              0.000000             0.000000                  0.0   \n",
       "2017-08-01              0.000000             0.000000                  0.0   \n",
       "2017-09-01              0.000000             0.000000                  0.0   \n",
       "2017-10-01             -0.671247            -0.223749                  0.0   \n",
       "2017-11-01              0.044214            -0.209011                  0.0   \n",
       "\n",
       "               insei_gemini_final  insei_indobert_lagged_raw  \\\n",
       "year_month_dt                                                  \n",
       "2017-07-01                   50.0                   0.018024   \n",
       "2017-08-01                   50.0                   0.098984   \n",
       "2017-09-01                   50.0                  -0.078912   \n",
       "2017-10-01                   50.0                  -0.052705   \n",
       "2017-11-01                   50.0                   0.044486   \n",
       "\n",
       "               insei_indolem_lagged_raw  insei_mdeberta_lagged_raw  \\\n",
       "year_month_dt                                                        \n",
       "2017-07-01                     0.264608                   0.222023   \n",
       "2017-08-01                     0.229115                   0.142892   \n",
       "2017-09-01                     0.011876                  -0.050584   \n",
       "2017-10-01                     0.018444                  -0.051758   \n",
       "2017-11-01                     0.115167                   0.095657   \n",
       "\n",
       "               insei_gemini_lagged_raw  Rate  year_month_str  \n",
       "year_month_dt                                                 \n",
       "2017-07-01                    0.230769  0.22         2017-07  \n",
       "2017-08-01                    0.296296 -0.07         2017-08  \n",
       "2017-09-01                    0.048780  0.13         2017-09  \n",
       "2017-10-01                    0.040000  0.01         2017-10  \n",
       "2017-11-01                    0.250000  0.20         2017-11  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f643d9",
   "metadata": {},
   "source": [
    "Loads the aligned dataset insei_all_model_cpi_aligned_lag2.csv, which contains monthly observations of the CPI Inflation Rate and the corresponding 2-month lagged sentiment indices from four models (IndoBERT, IndoLEM, mDeBERTa, Gemini). \n",
    "\n",
    "The date column is converted to a datetime object and set as the index. A  temporal split is defined using CUTOFF_DATE = \"2024-01-01\".\n",
    "- Training Set (2017–2023): 82 months (Jan 2017 – Dec 2023) period covers pre-pandemic stability, the COVID-19 shock, and the initial recovery. Used to fit model parameters.\n",
    "- Testing Set (2024–2025): This forecast horizon tests the models' ability to generalize to the most recent economic conditions. Used solely for out-of-sample evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc3ed7",
   "metadata": {},
   "source": [
    "# Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffa40605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- VAR_Baseline_AR_Only ---\n",
      "MAE:  0.3499\n",
      "RMSE: 0.5002\n",
      "R2:   -0.0017\n",
      "------------------------------\n",
      "--- VAR_Hybrid_insei_indobert_raw ---\n",
      "MAE:  0.3561\n",
      "RMSE: 0.5042\n",
      "R2:   -0.0176\n",
      "------------------------------\n",
      "VAR Improvement with insei_indobert_raw: -0.0039\n",
      "--- VAR_Hybrid_insei_indolem_raw ---\n",
      "MAE:  0.3598\n",
      "RMSE: 0.5086\n",
      "R2:   -0.0355\n",
      "------------------------------\n",
      "VAR Improvement with insei_indolem_raw: -0.0084\n",
      "--- VAR_Hybrid_insei_mdeberta_raw ---\n",
      "MAE:  0.3545\n",
      "RMSE: 0.5065\n",
      "R2:   -0.0270\n",
      "------------------------------\n",
      "VAR Improvement with insei_mdeberta_raw: -0.0063\n",
      "--- VAR_Hybrid_insei_gemini_raw ---\n",
      "MAE:  0.3582\n",
      "RMSE: 0.5096\n",
      "R2:   -0.0395\n",
      "------------------------------\n",
      "VAR Improvement with insei_gemini_raw: -0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\stable_diff_model\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\Lenovo\\.conda\\envs\\stable_diff_model\\Lib\\site-packages\\statsmodels\\tsa\\deterministic.py:308: UserWarning: Only PeriodIndexes, DatetimeIndexes with a frequency set, RangesIndexes, and Index with a unit increment support extending. The index is set will contain the position relative to the data length.\n",
      "  fcast_index = self._extend_index(index, steps, forecast_index)\n",
      "c:\\Users\\Lenovo\\.conda\\envs\\stable_diff_model\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\Lenovo\\.conda\\envs\\stable_diff_model\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\Lenovo\\.conda\\envs\\stable_diff_model\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\Lenovo\\.conda\\envs\\stable_diff_model\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "# Define a separate function just for the Baseline\n",
    "def run_baseline_ar(train, test):\n",
    "    ar_model = AutoReg(train[TARGET_COL].dropna(), lags=12, old_names=False).fit()\n",
    "    \n",
    "    pred_start = len(train)\n",
    "    pred_end = len(train) + len(test) - 1\n",
    "    preds_base = ar_model.predict(start=pred_start, end=pred_end, dynamic=False).values\n",
    "    \n",
    "    test_clean = test[TARGET_COL].iloc[-len(preds_base):]\n",
    "    # Calculate and PRINT metrics only once\n",
    "    return calculate_metrics(test_clean, preds_base, \"VAR_Baseline_AR_Only\")\n",
    "\n",
    "# Modify comparison function to ACCEPT the baseline metrics\n",
    "def run_var_hybrid_only(train, test, sentiment_col, baseline_metrics):\n",
    "    #  SCENARIO B: Hybrid (Bi-variate VAR) \n",
    "    cols = [TARGET_COL, sentiment_col]\n",
    "    train_var = train[cols].dropna()\n",
    "    test_var = test[cols].dropna()\n",
    "    \n",
    "    model = VAR(train_var)\n",
    "    model_fitted = model.fit(maxlags=12, ic='bic')    \n",
    "    lag_order = model_fitted.k_ar\n",
    "    \n",
    "    history = train_var.values[-lag_order:].tolist()\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(len(test_var)):\n",
    "        input_data = np.array(history[-lag_order:])\n",
    "        fc = model_fitted.forecast(y=input_data, steps=1)\n",
    "        predictions.append(fc[0][0])\n",
    "        history.append(test_var.iloc[i].values)\n",
    "        \n",
    "    metrics_hyb = calculate_metrics(test_var[TARGET_COL], predictions, f\"VAR_Hybrid_{sentiment_col}\")\n",
    "    \n",
    "    # Compare with the pre-calculated baseline\n",
    "    imp = baseline_metrics['RMSE'] - metrics_hyb['RMSE']\n",
    "    print(f\"VAR Improvement with {sentiment_col}: {imp:.4f}\")\n",
    "    \n",
    "    return metrics_hyb\n",
    "\n",
    "baseline_metrics = run_baseline_ar(train_df, test_df)\n",
    "results_summary.append(baseline_metrics)\n",
    "\n",
    "for sent in SENTIMENT_COLS:\n",
    "    hyb_metrics = run_var_hybrid_only(train_df, test_df, sent, baseline_metrics)\n",
    "    results_summary.append(hyb_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866c9719",
   "metadata": {},
   "source": [
    "VAR is a system of equations where every variable is \"endogenous\" (they all influence each other). This is crucial because Inflation affects Sentiment, and Sentiment affects Inflation.\n",
    "- The System of Equations:Let $Y_t$ be a vector containing both variables: $Y_t = \\begin{bmatrix} \\text{Rate}_t \\\\ \\text{Sentiment}_t \\end{bmatrix}$.The VAR(p) model is:$$Y_t = c + A_1 Y_{t-1} + A_2 Y_{t-2} + \\dots + A_p Y_{t-p} + e_t$$\n",
    "Where $A_k$ are $2 \\times 2$ coefficient matrices. Written out for Inflation ($y_t$):$$y_t = c_1 + \\sum_{k=1}^{p} a_{11,k} y_{t-k} + \\sum_{k=1}^{p} a_{12,k} S_{t-k} + e_{1,t}$$\n",
    "- Unlike Ridge, VAR captures the feedback loop. It understands that a shock to Sentiment today might raise Inflation tomorrow, which in turn scares the public and lowers Sentiment further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddde6390",
   "metadata": {},
   "source": [
    "The experiment follows a rigorous Baseline vs. Hybrid design:\n",
    "- Baseline (AutoReg): A univariate Autoregressive model is trained solely on the Rate column using AutoReg. It predicts the test set using only historical inflation inertia. This serves as the control group.\n",
    "- Hybrid (Bi-variate VAR): A Vector Autoregression model is trained on both Rate and the specific sentiment_col. The model order (lag length) is automatically selected using the Bayesian Information Criterion (BIC) to prevent overfitting. The forecast is generated using a rolling window approach, where the model uses the actual observed history (teacher forcing) to predict one step ahead for the entire test period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febedb08",
   "metadata": {},
   "source": [
    "Baseline Performance: The AR model yields an RMSE of 0.5002.\n",
    "\n",
    "Hybrid Performance: The hybrid models consistently underperfrom the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e13ccc",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0117a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ridge_Baseline_AR_Only ---\n",
      "MAE:  0.6197\n",
      "RMSE: 0.7509\n",
      "R2:   -0.1636\n",
      "------------------------------\n",
      "--- Ridge_Hybrid_insei_indobert_raw ---\n",
      "MAE:  0.5982\n",
      "RMSE: 0.7404\n",
      "R2:   -0.1311\n",
      "------------------------------\n",
      "Ridge Improvement with insei_indobert_raw: 0.0105\n",
      "--- Ridge_Hybrid_insei_indolem_raw ---\n",
      "MAE:  0.5826\n",
      "RMSE: 0.7299\n",
      "R2:   -0.0993\n",
      "------------------------------\n",
      "Ridge Improvement with insei_indolem_raw: 0.0210\n",
      "--- Ridge_Hybrid_insei_mdeberta_raw ---\n",
      "MAE:  0.5939\n",
      "RMSE: 0.7463\n",
      "R2:   -0.1492\n",
      "------------------------------\n",
      "Ridge Improvement with insei_mdeberta_raw: 0.0046\n",
      "--- Ridge_Hybrid_insei_gemini_raw ---\n",
      "MAE:  0.6220\n",
      "RMSE: 0.7728\n",
      "R2:   -0.2325\n",
      "------------------------------\n",
      "Ridge Improvement with insei_gemini_raw: -0.0219\n"
     ]
    }
   ],
   "source": [
    "def create_lags(data, sent_col=None, lags=12):\n",
    "    df_lag = pd.DataFrame()\n",
    "    # A. Autoregressive Features\n",
    "    for i in range(1, lags + 1):\n",
    "        df_lag[f\"Rate_L{i}\"] = data[TARGET_COL].shift(i)\n",
    "        \n",
    "    # B. Sentiment Features (Only if sent_col is provided)\n",
    "    if sent_col: \n",
    "        for i in range(1, lags + 1):\n",
    "            df_lag[f\"Sent_L{i}\"] = data[sent_col].shift(i)\n",
    "            \n",
    "    df_lag[\"Target\"] = data[TARGET_COL]\n",
    "    return df_lag.dropna()\n",
    "\n",
    "def run_ridge_baseline(train, test, lags=12):\n",
    "    # Prepare Data (No sentiment col passed)\n",
    "    train_feats = create_lags(train, sent_col=None, lags=lags)\n",
    "    test_feats = create_lags(test, sent_col=None, lags=lags)\n",
    "    \n",
    "    X_train = train_feats.drop(\"Target\", axis=1)\n",
    "    y_train = train_feats[\"Target\"]\n",
    "    X_test = test_feats.drop(\"Target\", axis=1)\n",
    "    y_test = test_feats[\"Target\"]\n",
    "    \n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "    \n",
    "    # Train & Predict\n",
    "    model = RidgeCV(cv=5).fit(X_train_s, y_train)\n",
    "    preds = model.predict(X_test_s)\n",
    "    \n",
    "    return calculate_metrics(y_test, preds, \"Ridge_Baseline_AR_Only\")\n",
    "\n",
    "def run_ridge_hybrid(train, test, sentiment_col, baseline_metrics, lags=12):\n",
    "    # Prepare Data (With Sentiment)\n",
    "    train_feats = create_lags(train, sentiment_col, lags)\n",
    "    test_feats = create_lags(test, sentiment_col, lags)\n",
    "    \n",
    "    X_train = train_feats.drop(\"Target\", axis=1)\n",
    "    y_train = train_feats[\"Target\"]\n",
    "    X_test = test_feats.drop(\"Target\", axis=1)\n",
    "    y_test = test_feats[\"Target\"]\n",
    "    \n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "    \n",
    "    # Train & Predict\n",
    "    model = RidgeCV(cv=5).fit(X_train_s, y_train)\n",
    "    preds = model.predict(X_test_s)\n",
    "    \n",
    "    metrics_hyb = calculate_metrics(y_test, preds, f\"Ridge_Hybrid_{sentiment_col}\")\n",
    "    \n",
    "    # Compare\n",
    "    imp = baseline_metrics['RMSE'] - metrics_hyb['RMSE']\n",
    "    print(f\"Ridge Improvement with {sentiment_col}: {imp:.4f}\")\n",
    "    \n",
    "    return metrics_hyb\n",
    "\n",
    "ridge_base_metrics = run_ridge_baseline(train_df, test_df)\n",
    "results_summary.append(ridge_base_metrics)\n",
    "\n",
    "for sent in SENTIMENT_COLS:\n",
    "    hyb = run_ridge_hybrid(train_df, test_df, sent, ridge_base_metrics)\n",
    "    results_summary.append(hyb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd43355",
   "metadata": {},
   "source": [
    "Ridge Regression (Linear Baseline vs. Hybrid)\n",
    "\n",
    "Ridge is a regularized linear model. It works by shrinking coefficients ($\\beta$) to prevent overfitting, which is critical when you have many correlated lags (e.g., Lag 1 is highly correlated with Lag 2).\n",
    "- The Objective Function: Ridge minimizes the Sum of Squared Errors (SSE) plus a penalty term ($\\lambda$) for the size of the coefficients:$$\\hat{\\beta} = \\arg\\min_{\\beta} \\left( \\sum_{t=1}^{T} (y_t - \\hat{y}_t)^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2 \\right)$$\n",
    "- Scenario A: AR Baseline (Control). The model predicts inflation ($y_t$) using only its own past values ($y_{t-k}$):$$y_t = \\alpha + \\sum_{k=1}^{12} \\beta_k y_{t-k} + \\epsilon_t$$\n",
    "- Scenario B: Hybrid Model (Test). The model includes the Sentiment Index ($S_{t-k}$) as an exogenous regressor:$$y_t = \\alpha + \\sum_{k=1}^{12} \\beta_k y_{t-k} + \\sum_{k=1}^{12} \\gamma_k S_{t-k} + \\epsilon_t$$\n",
    "\n",
    "- If $\\gamma_k \\neq 0$ and the error decreases, sentiment provides linear information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf44ea6",
   "metadata": {},
   "source": [
    "The create_lags function transforms the time-series problem into a supervised regression format. It generates 12 lags for the Inflation Rate ($Rate_{t-1} \\dots Rate_{t-12}$) and, for the hybrid models, 12 lags for the Sentiment Index.\n",
    "- Baseline: Uses only the 12 Rate lags as features.\n",
    "- Hybrid: Uses 12 Rate lags + 12 Sentiment lags.\n",
    "- Model: RidgeCV is used with 5-fold cross-validation to automatically select the optimal regularization strength ($\\alpha$), effectively handling the high correlation between lagged features. Standard scaling is applied to all features to ensure the regularization penalty is applied uniformly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c9038c",
   "metadata": {},
   "source": [
    "The Ridge results highlight a significant performance gain:\n",
    "- Baseline RMSE: 0.7509\n",
    "- Hybrid (IndoLEM) RMSE: 0.7299\n",
    "- Improvement: The inclusion of IndoLEM sentiment reduced the RMSE by 3%\n",
    "\n",
    "The linear models benefited most from the sentiment data. The substantial drop in error suggests that news sentiment helps correct the linear projections of inflation, likely by capturing \"shocks\" that purely autoregressive features miss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81353f89",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd892251",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOKBACK = 12\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "388507f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\stable_diff_model\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LSTM_Baseline_AR_Only ---\n",
      "MAE:  0.3514\n",
      "RMSE: 0.5008\n",
      "R2:   -0.0041\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\stable_diff_model\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LSTM_Hybrid_insei_indobert_raw ---\n",
      "MAE:  0.3595\n",
      "RMSE: 0.5051\n",
      "R2:   -0.0212\n",
      "------------------------------\n",
      "LSTM Improvement with insei_indobert_raw: -0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\stable_diff_model\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LSTM_Hybrid_insei_indolem_raw ---\n",
      "MAE:  0.3635\n",
      "RMSE: 0.5084\n",
      "R2:   -0.0349\n",
      "------------------------------\n",
      "LSTM Improvement with insei_indolem_raw: -0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\stable_diff_model\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LSTM_Hybrid_insei_mdeberta_raw ---\n",
      "MAE:  0.3617\n",
      "RMSE: 0.5072\n",
      "R2:   -0.0297\n",
      "------------------------------\n",
      "LSTM Improvement with insei_mdeberta_raw: -0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\stable_diff_model\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LSTM_Hybrid_insei_gemini_raw ---\n",
      "MAE:  0.3633\n",
      "RMSE: 0.5083\n",
      "R2:   -0.0342\n",
      "------------------------------\n",
      "LSTM Improvement with insei_gemini_raw: -0.0074\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(data, lookback):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - lookback):\n",
    "        X.append(data[i:i+lookback])\n",
    "        y.append(data[i+lookback, 0]) # 0 is always Rate\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Generic training function\n",
    "def train_predict_lstm(train, test, feature_cols, model_name):\n",
    "    # Data Prep\n",
    "    train_data = train[feature_cols].values\n",
    "    test_data = test[feature_cols].values\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    train_scaled = scaler.fit_transform(train_data)\n",
    "    test_scaled = scaler.transform(test_data)\n",
    "    \n",
    "    X_train, y_train = create_sequences(train_scaled, LOOKBACK)\n",
    "    n_features = len(feature_cols)\n",
    "    \n",
    "    # Model\n",
    "    model = Sequential([\n",
    "        LSTM(64, activation='relu', input_shape=(LOOKBACK, n_features), return_sequences=False),\n",
    "        Dropout(0.1),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0, callbacks=[early_stop])\n",
    "    \n",
    "    # Forecast Loop\n",
    "    current_window = train_scaled[-LOOKBACK:].reshape(1, LOOKBACK, n_features)\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(len(test_scaled)):\n",
    "        pred_scaled = model.predict(current_window, verbose=0)[0, 0]\n",
    "        predictions.append(pred_scaled)\n",
    "        \n",
    "        if n_features == 1:\n",
    "            new_row = np.array([[pred_scaled]]) \n",
    "        else:\n",
    "            next_sentiment = test_scaled[i, 1] \n",
    "            new_row = np.array([[pred_scaled, next_sentiment]])\n",
    "            \n",
    "        current_window = np.append(current_window[:, 1:, :], [new_row], axis=1)\n",
    "        \n",
    "    # Invert Scaling\n",
    "    dummy = np.zeros((len(predictions), n_features))\n",
    "    dummy[:, 0] = predictions\n",
    "    preds_final = scaler.inverse_transform(dummy)[:, 0]\n",
    "    \n",
    "    return calculate_metrics(test[TARGET_COL].values, preds_final, model_name)\n",
    "\n",
    "lstm_base_metrics = train_predict_lstm(train_df, test_df, [TARGET_COL], \"LSTM_Baseline_AR_Only\")\n",
    "results_summary.append(lstm_base_metrics)\n",
    "\n",
    "for sent in SENTIMENT_COLS:\n",
    "    # We use [TARGET_COL, sent]\n",
    "    hyb_metrics = train_predict_lstm(train_df, test_df, [TARGET_COL, sent], f\"LSTM_Hybrid_{sent}\")\n",
    "    \n",
    "    # Compare\n",
    "    imp = lstm_base_metrics['RMSE'] - hyb_metrics['RMSE']\n",
    "    print(f\"LSTM Improvement with {sent}: {imp:.4f}\")\n",
    "    \n",
    "    results_summary.append(hyb_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a64a2f8",
   "metadata": {},
   "source": [
    "LSTM is a Recurrent Neural Network (RNN) designed to capture non-linear patterns and long-term dependencies (memory).\n",
    "- The Core Logic:At each time step $t$, the LSTM cell takes input $x_t$ (Rate + Sentiment) and the previous hidden state $h_{t-1}$. It computes:\n",
    "    1. Forget Gate ($f_t$): What to throw away from memory.$$f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)$$\n",
    "    2. Input Gate ($i_t$): What new information to store.$$i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)$$\n",
    "    3. Cell State ($C_t$): The long-term memory update.$$C_t = f_t * C_{t-1} + i_t * \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)$$\n",
    "    4. Output Gate ($o_t$): The prediction for the next step.$$h_t = o_t * \\tanh(C_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588a1a36",
   "metadata": {},
   "source": [
    "The LSTM architecture consists of a single layer with 64 units (relu activation), followed by a Dropout layer (0.1) to prevent overfitting, and a Dense output layer.\n",
    "- Input Structure: The data is windowed with a LOOKBACK of 12 months.\n",
    "    - Baseline: Input shape (Batch, 12, 1) containing only Rate history.\n",
    "    - Hybrid: Input shape (Batch, 12, 2) containing Rate and Sentiment history\n",
    "- Training: The model is trained for 50 epochs with EarlyStopping to halt training when the loss plateaus.\n",
    "- Forecasting: A rolling forecast loop is implemented. For each step in the test set, the model predicts $t+1$. Crucially, for the hybrid model, the known sentiment at time $t$ (which corresponds to news from $t-2$ due to the lag) is fed into the model to predict the inflation at $t+1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5c543b",
   "metadata": {},
   "source": [
    "The LSTM results are counter-intuitive:\n",
    "- Baseline RMSE:0.5009\n",
    "- Hybrid (IndoBERT) RMSE: 0.5045\n",
    "- Result: The sentiment index actually increased the error (negative improvement) for IndoBERT and others. (-<1%)\n",
    "\n",
    "Deep learning models are data-hungry. With only 82 training samples, the added complexity of a second feature (sentiment) likely introduced more variance than signal, causing the model to overfit the noise rather than learn the relationship. This finding suggests that for small macroeconomic datasets, simpler econometric models (VAR) or regularized linear models (Ridge) are superior to deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaa8833",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49ced24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Performing Model: VAR_Baseline_AR_Only\n",
      "\n",
      "SUMMARY\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VAR_Baseline_AR_Only</td>\n",
       "      <td>0.349903</td>\n",
       "      <td>0.500217</td>\n",
       "      <td>-0.001693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LSTM_Baseline_AR_Only</td>\n",
       "      <td>0.351350</td>\n",
       "      <td>0.500815</td>\n",
       "      <td>-0.004090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VAR_Hybrid_insei_indobert_raw</td>\n",
       "      <td>0.356089</td>\n",
       "      <td>0.504162</td>\n",
       "      <td>-0.017555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LSTM_Hybrid_insei_indobert_raw</td>\n",
       "      <td>0.359506</td>\n",
       "      <td>0.505053</td>\n",
       "      <td>-0.021155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VAR_Hybrid_insei_mdeberta_raw</td>\n",
       "      <td>0.354518</td>\n",
       "      <td>0.506502</td>\n",
       "      <td>-0.027023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LSTM_Hybrid_insei_mdeberta_raw</td>\n",
       "      <td>0.361711</td>\n",
       "      <td>0.507165</td>\n",
       "      <td>-0.029713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LSTM_Hybrid_insei_gemini_raw</td>\n",
       "      <td>0.363312</td>\n",
       "      <td>0.508258</td>\n",
       "      <td>-0.034156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTM_Hybrid_insei_indolem_raw</td>\n",
       "      <td>0.363509</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>-0.034905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VAR_Hybrid_insei_indolem_raw</td>\n",
       "      <td>0.359836</td>\n",
       "      <td>0.508591</td>\n",
       "      <td>-0.035512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VAR_Hybrid_insei_gemini_raw</td>\n",
       "      <td>0.358160</td>\n",
       "      <td>0.509564</td>\n",
       "      <td>-0.039477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ridge_Hybrid_insei_indolem_raw</td>\n",
       "      <td>0.582591</td>\n",
       "      <td>0.729878</td>\n",
       "      <td>-0.099283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge_Hybrid_insei_indobert_raw</td>\n",
       "      <td>0.598243</td>\n",
       "      <td>0.740370</td>\n",
       "      <td>-0.131112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ridge_Hybrid_insei_mdeberta_raw</td>\n",
       "      <td>0.593948</td>\n",
       "      <td>0.746273</td>\n",
       "      <td>-0.149221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge_Baseline_AR_Only</td>\n",
       "      <td>0.619744</td>\n",
       "      <td>0.750915</td>\n",
       "      <td>-0.163563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ridge_Hybrid_insei_gemini_raw</td>\n",
       "      <td>0.622046</td>\n",
       "      <td>0.772835</td>\n",
       "      <td>-0.232486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model       MAE      RMSE        R2\n",
       "0              VAR_Baseline_AR_Only  0.349903  0.500217 -0.001693\n",
       "10            LSTM_Baseline_AR_Only  0.351350  0.500815 -0.004090\n",
       "1     VAR_Hybrid_insei_indobert_raw  0.356089  0.504162 -0.017555\n",
       "11   LSTM_Hybrid_insei_indobert_raw  0.359506  0.505053 -0.021155\n",
       "3     VAR_Hybrid_insei_mdeberta_raw  0.354518  0.506502 -0.027023\n",
       "13   LSTM_Hybrid_insei_mdeberta_raw  0.361711  0.507165 -0.029713\n",
       "14     LSTM_Hybrid_insei_gemini_raw  0.363312  0.508258 -0.034156\n",
       "12    LSTM_Hybrid_insei_indolem_raw  0.363509  0.508442 -0.034905\n",
       "2      VAR_Hybrid_insei_indolem_raw  0.359836  0.508591 -0.035512\n",
       "4       VAR_Hybrid_insei_gemini_raw  0.358160  0.509564 -0.039477\n",
       "7    Ridge_Hybrid_insei_indolem_raw  0.582591  0.729878 -0.099283\n",
       "6   Ridge_Hybrid_insei_indobert_raw  0.598243  0.740370 -0.131112\n",
       "8   Ridge_Hybrid_insei_mdeberta_raw  0.593948  0.746273 -0.149221\n",
       "5            Ridge_Baseline_AR_Only  0.619744  0.750915 -0.163563\n",
       "9     Ridge_Hybrid_insei_gemini_raw  0.622046  0.772835 -0.232486"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = pd.DataFrame(results_summary)\n",
    "summary_df = summary_df.sort_values(\"RMSE\")\n",
    "summary_df.to_csv(\"forecasting_results_raw.csv\", index=False)\n",
    "\n",
    "best_model = summary_df.iloc[0][\"Model\"]\n",
    "print(f\"Best Performing Model: {best_model}\\n\")\n",
    "\n",
    "print(\"SUMMARY\")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4743d113",
   "metadata": {},
   "source": [
    "Top performaer was a baseline model which prrof that with raw INSEI Index is no better than without it. That is why lets next try with the lagged index."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable_diff_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
