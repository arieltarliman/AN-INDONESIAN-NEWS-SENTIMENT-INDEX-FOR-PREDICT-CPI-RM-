{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecbf2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import google.genai as genai\n",
    "\n",
    "# Load all keys\n",
    "load_dotenv(override=True)\n",
    "API_KEYS = [\n",
    "    os.getenv(\"GEMINI_KEY_5\"),\n",
    "    os.getenv(\"GEMINI_KEY_6\"),\n",
    "]\n",
    "MODEL_ID = \"models/gemini-2.5-flash\"\n",
    "\n",
    "# Initialize first client\n",
    "key_index = 0\n",
    "client = genai.Client(api_key=API_KEYS[key_index])\n",
    "\n",
    "# Utility\n",
    "def switch_api_key():\n",
    "    \"\"\"Switch to next available key. Return False if none left.\"\"\"\n",
    "    global key_index, client\n",
    "    if key_index + 1 < len(API_KEYS):\n",
    "        key_index += 1\n",
    "        new_key = API_KEYS[key_index]\n",
    "        client = genai.Client(api_key=new_key)\n",
    "        print(f\"Switched to API key #{key_index+1}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"All API keys exhausted.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935cbf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch classify function\n",
    "def batch_classify_inflation(texts, max_retries=3):\n",
    "    joined = \"\\n\\n\".join([f\"{i+1}. {t[:1000]}\" for i, t in enumerate(texts)])\n",
    "    prompt = f\"\"\"\n",
    "    Kamu adalah analis ekonomi makro yang menilai berita tentang inflasi di Indonesia khususnya pada index Indeks Harga Konsumen (CPI) di Indonesia.\n",
    "\n",
    "    Untuk setiap teks berita berikut, berikan:\n",
    "    - Label: Inflation, Deflation, atau Neutral\n",
    "    - Alasan singkat (1 kalimat) mengapa kamu memilih label itu.\n",
    "\n",
    "    Format jawaban (gunakan tanda | sebagai pemisah label dan alasan):\n",
    "    1. Inflation | Kenaikan harga minyak mendorong tekanan inflasi.\n",
    "    2. Deflation | Penurunan permintaan menyebabkan harga turun.\n",
    "    3. Neutral | Hanya laporan data tanpa indikasi tekanan harga.\n",
    "\n",
    "    Teks berita:\n",
    "    {joined}\n",
    "    \"\"\"\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=MODEL_ID,\n",
    "                contents=prompt,\n",
    "            )\n",
    "\n",
    "            raw_output = getattr(response, \"text\", None)\n",
    "            if raw_output is None and hasattr(response, \"candidates\"):\n",
    "                raw_output = response.candidates[0].content.parts[0].text\n",
    "            if raw_output is None:\n",
    "                raw_output = str(response)\n",
    "\n",
    "            matches = re.findall(\n",
    "                r'^\\s*\\d+\\.\\s*([A-Za-z]+)\\s*\\|\\s*(.+)$',\n",
    "                raw_output,\n",
    "                flags=re.MULTILINE,\n",
    "            )\n",
    "\n",
    "            labels, reasons = [], []\n",
    "            for label, reason in matches:\n",
    "                label = label.capitalize()\n",
    "                if label not in [\"Inflation\", \"Deflation\", \"Neutral\"]:\n",
    "                    label = \"Neutral\"\n",
    "                labels.append(label)\n",
    "                reasons.append(reason.strip())\n",
    "\n",
    "            # Ensure batch length consistency\n",
    "            n = len(texts)\n",
    "            while len(labels) < n:\n",
    "                labels.append(\"Neutral\")\n",
    "                reasons.append(\"Tidak ada alasan diberikan.\")\n",
    "            if len(labels) > n:\n",
    "                labels, reasons = labels[:n], reasons[:n]\n",
    "            return labels, reasons\n",
    "\n",
    "        except Exception as e:\n",
    "            err = str(e)\n",
    "            print(f\"Exception in batch_classify_inflation: {type(e).__name__} → {err}\")\n",
    "\n",
    "            if \"RESOURCE_EXHAUSTED\" in err:\n",
    "                print(f\"API key #{key_index+1} quota exhausted.\")\n",
    "                if not switch_api_key():\n",
    "                    raise RuntimeError(\"All keys exhausted – stop job now.\")\n",
    "                else:\n",
    "                    time.sleep(10)\n",
    "                    return batch_classify_inflation(texts)  # retry with new key\n",
    "\n",
    "            elif \"503\" in err or \"UNAVAILABLE\" in err:\n",
    "                wait = 60 * (attempt + 1)\n",
    "                print(f\"Gemini overloaded, waiting {wait}s before retry...\")\n",
    "                time.sleep(wait)\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                print(\"Unhandled error, retrying after short delay...\")\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "\n",
    "    print(\"All retries failed. Defaulting to Neutral.\")\n",
    "    n = len(texts)\n",
    "    return [\"Neutral\"] * n, [\"Server overloaded or quota limit.\"] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3344d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_batch_label(df, batch_size=5, checkpoint_path=\"checkpoint_tempo.csv\",\n",
    "                     delay_sec=6, retry_wait=60, max_retries=3):\n",
    "\n",
    "    if \"label\" not in df.columns:\n",
    "        df[\"label\"] = [None] * len(df)\n",
    "    if \"label_reason\" not in df.columns:\n",
    "        df[\"label_reason\"] = [None] * len(df)\n",
    "\n",
    "    start_i = 0\n",
    "\n",
    "    # Resume safely\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Resuming from checkpoint: {checkpoint_path}\")\n",
    "        df_ckpt = pd.read_csv(checkpoint_path)\n",
    "        if len(df_ckpt) == len(df):\n",
    "            for col in [\"label\", \"label_reason\"]:\n",
    "                if col in df_ckpt.columns:\n",
    "                    df[col] = df_ckpt[col]\n",
    "        unlabeled_idx = df[\"label\"].isna()\n",
    "        if unlabeled_idx.any():\n",
    "            start_i = unlabeled_idx.idxmax()\n",
    "        else:\n",
    "            print(\"All rows already labeled — nothing to resume.\")\n",
    "            return df\n",
    "        print(f\"Resuming from row {start_i}\")\n",
    "\n",
    "    # Main loop\n",
    "    for i in tqdm(range(start_i, len(df), batch_size)):\n",
    "        batch = df[\"clean_text\"].iloc[i:i+batch_size].tolist()\n",
    "        n_batch = len(batch)\n",
    "\n",
    "        try:\n",
    "            labels, reasons = batch_classify_inflation(batch)\n",
    "        except RuntimeError as e:\n",
    "            print(f\"{e}. Saving checkpoint and stopping.\")\n",
    "            tmp_path = checkpoint_path + \".tmp\"\n",
    "            df.to_csv(tmp_path, index=False)\n",
    "            os.replace(tmp_path, checkpoint_path)\n",
    "            print(f\"Saved progress before stopping at row {i}.\")\n",
    "            return df\n",
    "\n",
    "        if not labels:\n",
    "            labels = [\"Neutral\"] * n_batch\n",
    "            reasons = [\"Failed request\"] * n_batch\n",
    "\n",
    "        # Match batch size\n",
    "        if len(labels) != n_batch:\n",
    "            labels = (labels + [\"Neutral\"] * n_batch)[:n_batch]\n",
    "        if len(reasons) != n_batch:\n",
    "            reasons = (reasons + [\"Unknown\"] * n_batch)[:n_batch]\n",
    "\n",
    "        df.loc[i:i+batch_size-1, \"label\"] = labels\n",
    "        df.loc[i:i+batch_size-1, \"label_reason\"] = reasons\n",
    "\n",
    "        # Save checkpoint every 100 rows or at end\n",
    "        if (i % 100 == 0) or (i + batch_size >= len(df)):\n",
    "            tmp_path = checkpoint_path + \".tmp\"\n",
    "            df.to_csv(tmp_path, index=False)\n",
    "            os.replace(tmp_path, checkpoint_path)\n",
    "            print(f\"Checkpoint saved safely at row {i}\")\n",
    "\n",
    "        time.sleep(delay_sec)\n",
    "\n",
    "    os.makedirs(\"result\", exist_ok=True)\n",
    "    out_path = \"result/df_tempo_labeled.csv\"\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Labeling complete → saved to {out_path}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8b5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved safely at row 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [02:31<00:20, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved safely at row 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [02:45<00:00, 20.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling complete → saved to result/df_tempo_labeled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN\n",
    "df_tempo = pd.read_csv(\"result/df_tempo.csv\")\n",
    "df_tempo_labeled = safe_batch_label(df_tempo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
